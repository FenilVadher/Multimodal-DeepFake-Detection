{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fa5cd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Environment Setup ---\n",
    "import torch\n",
    "from transformers import DebertaTokenizer, DebertaForSequenceClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6863b52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on CPU with 4 threads\n"
     ]
    }
   ],
   "source": [
    "# Force CPU usage\n",
    "device = torch.device(\"cpu\")\n",
    "torch.set_num_threads(4)  # Optimize for 4 CPU cores\n",
    "print(\"Running on CPU with 4 threads\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4b20fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 21417 real samples and 23481 fake samples\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Data Preparation with Custom Dataset ---\n",
    "def load_custom_data(real_data_path, fake_data_path):\n",
    "    \"\"\"\n",
    "    Load your custom dataset from files\n",
    "    Expected file formats: CSV or TXT\n",
    "    \n",
    "    CSV Format should have at least one column named 'text'\n",
    "    TXT Format should have one text sample per line\n",
    "    \"\"\"\n",
    "    # For CSV files\n",
    "    if real_data_path.endswith('.csv'):\n",
    "        real_df = pd.read_csv(real_data_path)\n",
    "        fake_df = pd.read_csv(fake_data_path)\n",
    "        real_texts = real_df['text'].tolist()\n",
    "        fake_texts = fake_df['text'].tolist()\n",
    "    \n",
    "    # For TXT files\n",
    "    elif real_data_path.endswith('.txt'):\n",
    "        with open(real_data_path, 'r', encoding='utf-8') as f:\n",
    "            real_texts = [line.strip() for line in f if line.strip()]\n",
    "        with open(fake_data_path, 'r', encoding='utf-8') as f:\n",
    "            fake_texts = [line.strip() for line in f if line.strip()]\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Use CSV or TXT files.\")\n",
    "    \n",
    "    # Verify data loaded correctly\n",
    "    print(f\"Loaded {len(real_texts)} real samples and {len(fake_texts)} fake samples\")\n",
    "    assert len(real_texts) > 0 and len(fake_texts) > 0, \"No data loaded - check your files\"\n",
    "    \n",
    "    texts = real_texts + fake_texts\n",
    "    labels = [0]*len(real_texts) + [1]*len(fake_texts)\n",
    "    \n",
    "    return train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- REPLACE THESE PATHS WITH YOUR ACTUAL FILES ---\n",
    "real_data_path = \"/Users/fenilvadher/Documents/Collage Data/SEM - 6/AI/AI Project/Fake-Real News Dataset/True.csv\"  # or .txt\n",
    "fake_data_path = \"/Users/fenilvadher/Documents/Collage Data/SEM - 6/AI/AI Project/Fake-Real News Dataset/Fake.csv\"  # or .txt\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels = load_custom_data(real_data_path, fake_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07707628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Dataset Class ---\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fafd756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs.hf.co/microsoft/deberta-base/b8dd0f54523e221f5e4dc2457d61da3115ecfe859c01010954d39e25b0ecf271?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1744351576&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NDM1MTU3Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9taWNyb3NvZnQvZGViZXJ0YS1iYXNlL2I4ZGQwZjU0NTIzZTIyMWY1ZTRkYzI0NTdkNjFkYTMxMTVlY2ZlODU5YzAxMDEwOTU0ZDM5ZTI1YjBlY2YyNzE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=B%7EoDhgj0POWQEqwzWNbfXzXQZX5tqszPogihbKzUsXRWYSa0uGW8uKb53H1RjuC51qPMSKmM5HHZ7H8dMcdLcB-%7EI7jl79y3eDFzRg1zWdvpaCW%7EDz6gPMK2zK%7EjRWgsw63951yFgIiiCYd5DBCX9NxgYieE-AP-5Y4c2lm41Z7F8Kj79n41XCsmFsGZWnK2OYXVOFI2DJlBORQ6ACqacL6fz9jeAs1AnontcdtRLFsHUfJeotVX%7ElO1BLj1lKh3AFKsmYmtFGSUPlvPFT8-b3Bs3UekqYvNNWoAxjncn31%7E5%7ECcg1F4hLk8UmP6RjD3XsKHwKKEQp4-IN1ZXaCy4A__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Initialize DeBERTa ---\n",
    "tokenizer = DebertaTokenizer.from_pretrained(\"microsoft/deberta-base\")\n",
    "model = DebertaForSequenceClassification.from_pretrained(\n",
    "    \"microsoft/deberta-base\",\n",
    "    num_labels=2\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b204627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. DataLoaders ---\n",
    "train_dataset = TextDataset(train_texts, train_labels, tokenizer)\n",
    "test_dataset = TextDataset(test_texts, test_labels, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba43d94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 8980/8980 [4:48:10<00:00,  1.93s/it, loss=0.0087]      \n",
      "Epoch 2: 100%|██████████| 8980/8980 [5:35:35<00:00,  2.24s/it, loss=0.00134]      \n"
     ]
    }
   ],
   "source": [
    "# --- 6. Training Loop ---\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "for epoch in range(2):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        inputs = {\n",
    "            \"input_ids\": batch[\"input_ids\"].to(device),\n",
    "            \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
    "            \"labels\": batch[\"labels\"].to(device)\n",
    "        }\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({\"loss\": total_loss / (progress_bar.n + 1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e2112e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to custom_deberta_detector.pth\n"
     ]
    }
   ],
   "source": [
    "# --- 8. Save Model ---\n",
    "torch.save(model.state_dict(), \"custom_deberta_detector.pth\")\n",
    "print(\"Model saved to custom_deberta_detector.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6eca696c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 9. Prediction Function ---\n",
    "def detect_deepfake(text):\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    ).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.softmax(outputs.logits, dim=1)[0]\n",
    "    \n",
    "    return {\n",
    "        \"prediction\": \"Fake\" if probs[1] > 0.5 else \"Real\",\n",
    "        \"confidence\": max(probs[0], probs[1]).item(),\n",
    "        \"real_prob\": f\"{probs[0].item():.2%}\",\n",
    "        \"fake_prob\": f\"{probs[1].item():.2%}\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e11ee831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing with sample from your dataset:\n",
      "\n",
      "Text: Donald Trump s White House is in chaos, and they are trying to cover it up. Their Russia problems are mounting by the hour, and they refuse to acknowledge that there are problems surrounding all of this. To them, it s  fake news,  or a  hoax.  However, the facts bear things out differently, and it seems that there are now cracks in the Congressional public leadership.Chuck Grassley (R-Iowa), who heads the Senate Judiciary Committee, is fed up. He is now demanding that Donald Trump, Jr. and former 2016 Trump Campaign Manager Paul Manafort testify before his committee regarding the now infamous shady meeting between Donald Trump and the shady Russian lawyer who promised dirt on 2016 Democratic Presidential nominee Hillary Clinton. In fact, this information is due, well, NOW. This demand sends a few signals to team Trump   most notably that they should not fire Special Counsel Robert Mueller under any circumstances, despite the fact that it seems that this seems to be what Trump s White House is laying the groundwork, so to speak, to do as we speak.Here is the tweet regarding Grassley s warning:Also, anyone who thinks that Senator Grassley and the rest of the Senate are not serious about this only needs to look at the warning that has already been given: Trump Jr. and Manafort will either follow orders, or be served with subpoenas that force them to comply. If they refuse, they will be held in contempt of Congress, which carries with it serious jail time.Even the cruel, craven creatures within the GOP are sick of Donald Trump s corruption and his scandal-ridden White House. They are angry that he staged a hostile takeover of their party, first with birtherism and giving them a permanently racist label all while decimating all efforts that were made to pretend the Republican Party isn t a hotbed of racism, and while turning their worlds upside down, and with it, the nation. It seems that old-timers like Grassley, who are clearly sick of Trump s bullshit, just might be the ones who could save the republic. All they need is a bit of courage.Featured image via Win McNamee/Getty Images\n",
      "Prediction: Fake\n",
      "Confidence: 100.00%\n",
      "Real Probability: 0.00%\n",
      "Fake Probability: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# --- Example Usage with Custom Data ---\n",
    "print(\"\\nTesting with sample from your dataset:\")\n",
    "sample_text = test_texts[0]  # Using your actual test data\n",
    "result = detect_deepfake(sample_text)\n",
    "print(f\"\\nText: {sample_text}\")\n",
    "print(f\"Prediction: {result['prediction']}\")\n",
    "print(f\"Confidence: {result['confidence']:.2%}\")\n",
    "print(f\"Real Probability: {result['real_prob']}\")\n",
    "print(f\"Fake Probability: {result['fake_prob']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02864d11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
