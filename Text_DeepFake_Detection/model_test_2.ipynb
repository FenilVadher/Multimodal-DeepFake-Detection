{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9683f5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "from safetensors.torch import load_file\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63d56e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 1. Load Model and Tokenizer ---\n",
    "model_path = \"/Users/fenilvadher/Documents/Collage Data/SEM - 6/AI/AI Project/bert_fake_news_model/model.safetensors\"\n",
    "tokenizer_path = \"/Users/fenilvadher/Documents/Collage Data/SEM - 6/AI/AI Project/bert_fake_news_tokenizer\"\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=2\n",
    ")\n",
    "model.load_state_dict(load_file(model_path))\n",
    "tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8eba7ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Improved Data Loader (Handles All Formats) ---\n",
    "def load_new_data(data_path):\n",
    "    \"\"\"Load CSV or folder-based dataset, auto-converting labels to 0/1\"\"\"\n",
    "    if data_path.endswith('.csv'):\n",
    "        df = pd.read_csv(data_path)\n",
    "        texts = df['text'].tolist()\n",
    "        \n",
    "        # Convert any label format to 0/1\n",
    "        if 'label' in df.columns:\n",
    "            labels = df['label'].apply(lambda x: 0 if str(x).lower() in ['0', 'real', 'true'] else 1).tolist()\n",
    "        else:\n",
    "            raise ValueError(\"CSV must contain 'text' and 'label' columns\")\n",
    "    else:\n",
    "        # Folder-based loading\n",
    "        texts, labels = [], []\n",
    "        label_map = {'real': 0, 'fake': 1}\n",
    "        for label_name, label_val in label_map.items():\n",
    "            folder_path = os.path.join(data_path, label_name)\n",
    "            if os.path.exists(folder_path):\n",
    "                for file in os.listdir(folder_path):\n",
    "                    with open(os.path.join(folder_path, file), 'r', encoding='utf-8') as f:\n",
    "                        texts.append(f.read())\n",
    "                        labels.append(label_val)\n",
    "    \n",
    "    return texts, np.array(labels)  # Ensure labels are numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "340b8701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Batch Prediction ---\n",
    "def predict_batch(texts, batch_size=8):\n",
    "    predictions = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Predicting\"):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        inputs = tokenizer(\n",
    "            batch,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=512,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\"\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            batch_preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "            predictions.extend(batch_preds)\n",
    "    return np.array(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c0f2ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 792/792 [51:46<00:00,  3.92s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance on New Dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real     0.4588    0.0369    0.0683      3171\n",
      "        Fake     0.4977    0.9564    0.6547      3164\n",
      "\n",
      "    accuracy                         0.4961      6335\n",
      "   macro avg     0.4783    0.4966    0.3615      6335\n",
      "weighted avg     0.4782    0.4961    0.3612      6335\n",
      "\n",
      "Accuracy: 49.61%\n",
      "\n",
      "Error Analysis (3192 misclassified):\n",
      "Error: 'int' object is not subscriptable\n",
      "Check:\n",
      "- Your data path exists\n",
      "- CSV has 'text' column\n",
      "- Labels are in [0,1,'real','fake','true','false'] format\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Main Execution ---\n",
    "try:\n",
    "    # Load data (replace with your path)\n",
    "    new_texts, new_labels = load_new_data(\"/Users/fenilvadher/Documents/Collage Data/SEM - 6/AI/AI Project/news.csv\")  # or folder path\n",
    "    \n",
    "    # Predict\n",
    "    new_predictions = predict_batch(new_texts)\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"\\nPerformance on New Dataset:\")\n",
    "    print(classification_report(new_labels, new_predictions, \n",
    "                              target_names=[\"Real\", \"Fake\"],\n",
    "                              digits=4))\n",
    "    print(f\"Accuracy: {accuracy_score(new_labels, new_predictions):.2%}\")\n",
    "    \n",
    "    # Error analysis\n",
    "    errors = pd.DataFrame({\n",
    "        'text': [t[:200] + \"...\" for t in new_texts],\n",
    "        'true': new_labels,\n",
    "        'predicted': new_predictions\n",
    "    }).query(\"true != predicted\")\n",
    "    \n",
    "    if not errors.empty:\n",
    "        print(f\"\\nError Analysis ({len(errors)} misclassified):\")\n",
    "        print(errors.sample(min(3, len(errors))[['text', 'true', 'predicted']]))\n",
    "    else:\n",
    "        print(\"\\nPerfect accuracy on this dataset!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    print(\"Check:\")\n",
    "    print(\"- Your data path exists\")\n",
    "    print(\"- CSV has 'text' column\")\n",
    "    print(\"- Labels are in [0,1,'real','fake','true','false'] format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d385027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Misclassified Texts:\n",
      "\n",
      "Case 1:\n",
      "Text: U.S. Secretary of State John F. Kerry said Monday that he will stop in Paris later this week, amid criticism that no top American officials attended Sunday’s unity march against terrorism.\n",
      "\n",
      "Kerry said...\n",
      "True: Real, Predicted: Fake\n",
      "\n",
      "Case 2:\n",
      "Text: It's primary day in New York and front-runners Hillary Clinton and Donald Trump are leading in the polls.\n",
      "\n",
      "Trump is now vowing to win enough delegates to clinch the Republican nomination and prevent a...\n",
      "True: Real, Predicted: Fake\n",
      "\n",
      "Case 3:\n",
      "Text: A Czech stockbroker who saved more than 650 Jewish children from Nazi Germany has died at the age of 106. Dubbed “Britain’s Schindler,” Nicholas Winton arranged to transport Jewish youngsters from Pra...\n",
      "True: Real, Predicted: Fake\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Analyze Mistakes ---\n",
    "mistakes = []\n",
    "for text, true_label, pred in zip(new_texts[:100], new_labels[:100], new_predictions[:100]):\n",
    "    if true_label != pred:\n",
    "        mistakes.append({\n",
    "            'text': text[:200] + \"...\",\n",
    "            'true': \"Real\" if true_label == 0 else \"Fake\",\n",
    "            'predicted': \"Real\" if pred == 0 else \"Fake\"\n",
    "        })\n",
    "\n",
    "print(\"\\nSample Misclassified Texts:\")\n",
    "for i, mistake in enumerate(mistakes[:3]):\n",
    "    print(f\"\\nCase {i+1}:\")\n",
    "    print(f\"Text: {mistake['text']}\")\n",
    "    print(f\"True: {mistake['true']}, Predicted: {mistake['predicted']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd52a87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
